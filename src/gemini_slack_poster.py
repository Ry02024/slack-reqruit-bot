import os
import requests
from bs4 import BeautifulSoup
from datetime import datetime
from zoneinfo import ZoneInfo
from google import genai

MESSAGE_FILE = "data/reqruit.txt"  # æ±‚äººæƒ…å ±è¦ç´„çµæœã‚’æ›¸ãå‡ºã™ãƒ•ã‚¡ã‚¤ãƒ«

class GeminiSlackPoster:
    """
    Gemini API ã‚’åˆ©ç”¨ã—ã¦æ±‚äººæƒ…å ±ã®è¦ç´„ã‚’ç”Ÿæˆã—ã€ãã®çµæœã‚’ Slack ã«æŠ•ç¨¿ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚
    """
    def __init__(self, gemini_api, slack_bot_token, slack_channel_id):
        self.gemini_api = gemini_api
        self.slack_bot_token = slack_bot_token
        self.slack_channel_id = slack_channel_id

        # Gemini ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ï¼ˆAPI ãƒãƒ¼ã‚¸ãƒ§ãƒ³: v1alphaï¼‰
        self.client = genai.Client(api_key=self.gemini_api, http_options={'api_version': 'v1alpha'})
        self.search_client = self.client.chats.create(
            model='gemini-2.0-flash-exp',
            config={'tools': [{'google_search': {}}]}
        )

    def robust_get(self, url, max_retries=3, timeout=20):
        for attempt in range(max_retries):
            try:
                r = requests.get(url, allow_redirects=True, timeout=timeout)
                return r
            except Exception:
                if attempt < max_retries - 1:
                    continue
                else:
                    return None

    def get_final_url(self, redirect_url):
        r = self.robust_get(redirect_url)
        return r.url if r else None

    def summary_client(self, original_text):
        summary_prompt = f"""
    ä»¥ä¸‹ã®æ–‡ç« ã‚’ã‚‚ã¨ã«ã€æ±‚äººæƒ…å ±ã®å„æ¡ˆä»¶ã‚’åˆ†ã‹ã‚Šã‚„ã™ãæ•´ç†ã—ã€æ¬¡ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§5ä»¶ã«ã¾ã¨ã‚ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    å›ç­”ã¯å¿…ãšãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§ã€ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³è¨˜æ³•ã‚„è£…é£¾ã¯ä½¿ç”¨ã›ãšã€çµµæ–‡å­—ã‚’åŠ¹æœçš„ã«è¿½åŠ ã—ã¦ãã ã•ã„ã€‚
    
    ã€æœŸå¾…ã™ã‚‹å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹ã€‘
    --------------------------------------------------
    ğŸ¢ æœ¬æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ç³»éšœãŒã„è€…æ±‚äººã¯ã“ã¡ã‚‰ã§ã™ï¼š
    
    1. ğŸ¢ æ ªå¼ä¼šç¤¾ãƒ–ãƒ¬ã‚¤ãƒ³ãƒ‘ãƒƒãƒ‰ - ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆï¼ˆã‚¸ãƒ¥ãƒ‹ã‚¢ãƒ¬ãƒ™ãƒ«ï¼‰
        ğŸ“ å‹¤å‹™åœ°: å…­æœ¬æœ¨ä¸€ä¸ç›®é§…ç›´çµï¼ˆè©³ç´°ä¸æ˜ï¼‰
        ğŸ’¼ è·ç¨®: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆ
        ğŸ’° çµ¦ä¸: å¹´å480ä¸‡å††ï½780ä¸‡å††
        â° å‹¤å‹™å½¢æ…‹: å¥‘ç´„ç¤¾å“¡ï¼ˆæ­£ç¤¾å“¡ç™»ç”¨åˆ¶åº¦ã‚ã‚Šï¼‰ã€ãƒ•ãƒ¬ãƒƒã‚¯ã‚¹ã‚¿ã‚¤ãƒ åˆ¶ï¼ˆã‚³ã‚¢ã‚¿ã‚¤ãƒ 11:00ï½15:00ï¼‰
        ğŸ” ç‰¹å¾´: ãƒ‡ãƒ¼ã‚¿åˆ†æãƒªãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚«ãƒ³ãƒ‘ãƒ‹ãƒ¼ã€å¹´é–“ä¼‘æ—¥127æ—¥ã€å…¬å¹³ãªè©•ä¾¡åˆ¶åº¦ã€éšœå®³è€…é›‡ç”¨å®Ÿç¸¾è±Šå¯Œã€‚ãƒ‡ãƒ¼ã‚¿æ´»ç”¨ã€AIãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰æ‹…å½“ã€‚
    
    2. ğŸ¢ ãƒ”ã‚¢ã‚¹æ ªå¼ä¼šç¤¾ - ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆ
        ğŸ“ å‹¤å‹™åœ°: æ±äº¬éƒ½ä¸­å¤®åŒº ã¾ãŸã¯ å¤§é˜ªåºœå¤§é˜ªå¸‚åŒ—åŒº
        ğŸ’¼ è·ç¨®: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆ
        ğŸ’° çµ¦ä¸: å¹´å480ä¸‡å††ï½
        â° å‹¤å‹™å½¢æ…‹: å¥‘ç´„ç¤¾å“¡ã€11:00ï½15:00ï¼‰
        ğŸ” ç‰¹å¾´: åŒ–ç²§å“ãƒ–ãƒ©ãƒ³ãƒ‰ã€é€šè²©ãƒ‡ãƒ¼ã‚¿åˆ†æã€æ­£ç¤¾å“¡ç™»ç”¨åˆ¶åº¦ã‚ã‚Šã€‚
    --------------------------------------------------
    
    ã€è¦ä»¶ã€‘
    - æœ€åˆã«ã€Œæœ¬æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ç³»éšœãŒã„è€…æ±‚äººã¯ã“ã¡ã‚‰ã§ã™ï¼šã€ã¨è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚
    - ãã‚Œãã‚Œã®æ±‚äººã«å¯¾ã—ã€ä¼æ¥­åï¼ˆğŸ¢ï¼‰ã€å‹¤å‹™åœ°ï¼ˆğŸ“ï¼‰ã€è·ç¨®ï¼ˆğŸ’¼ï¼‰ã€çµ¦ä¸ï¼ˆğŸ’°ï¼‰ã€å‹¤å‹™å½¢æ…‹ï¼ˆâ°ï¼‰ã€ç‰¹å¾´ï¼ˆğŸ”ï¼‰ã‚’æ˜è¨˜ã—ã¦ãã ã•ã„ã€‚
    - å¹´é½¢åˆ¶é™ãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚
    - å„ç¤¾ãŒæ¡ç”¨ã—ã¦ã„ã‚‹éšœå®³ã®ç¨®åˆ¥ã‚„å‰²åˆã€å…·ä½“çš„ãªæ¡ç”¨äººæ•°ã«é–¢ã™ã‚‹æƒ…å ±ãŒã‚ã‚Œã°ã€ãã‚Œã‚‚æ˜è¨˜ã—ã¦ãã ã•ã„ã€‚
    - æ–‡ä¸­ã®å¼•ç”¨ç•ªå·ï¼ˆ[1], [2], [7]ãªã©ï¼‰ã¯å¯èƒ½ãªé™ã‚Šç¶­æŒã—ã¦ãã ã•ã„ã€‚
    - æ–‡ç« ã¯ç°¡æ½”ã§æ˜ç­ã«ã€‚
    - å›ç­”ã¯ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§ã€ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³è¨˜æ³•ã‚„ãã®ä»–ã®è£…é£¾ã¯ä½¿ç”¨ã›ãšã€ä¸Šè¨˜ã®ã‚ˆã†ãªé©åˆ‡ãªçµµæ–‡å­—ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚
    
    ã€å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã€‘
    {original_text}
    """

        summary_response = self.client.models.generate_content(
            model="gemini-2.0-flash-exp",
            contents=summary_prompt
        )
        return summary_response.text.strip()

    def serch_references(self, response):
        if not response.candidates[0].grounding_metadata:
            return "æ¤œç´¢çµæœæƒ…å ± (grounding_metadata) ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        grounding_chunks = response.candidates[0].grounding_metadata.grounding_chunks
        if not grounding_chunks:
            return "URLãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã”è‡ªèº«ã§ã‚‚èª¿ã¹ã¦ã¿ã¦ä¸‹ã•ã„ã€‚"
        ref_lines = ["*å–å¾—ã—ãŸå‚ç…§ã‚µã‚¤ãƒˆä¸€è¦§:*"]
        for i, chunk in enumerate(grounding_chunks, start=1):
            redirect_url = chunk.web.uri
            final_url = self.get_final_url(redirect_url)
            if final_url is None:
                page_title = "ï¼ˆãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆå¤±æ•—ï¼‰"
            else:
                try:
                    resp = self.robust_get(final_url)
                    if resp is None:
                        page_title = "ï¼ˆå–å¾—å¤±æ•—ï¼‰"
                    elif resp.status_code == 200:
                        soup = BeautifulSoup(resp.text, "html.parser")
                        page_title = soup.title.string if soup.title else "ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ãªã—ï¼‰"
                    else:
                        page_title = f"ï¼ˆå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {resp.status_code}ï¼‰"
                except Exception as e:
                    page_title = f"ï¼ˆã‚¨ãƒ©ãƒ¼: {str(e)}ï¼‰"
            ref_lines.append(f"{i}. <{final_url}|{page_title}>")
        return "\n".join(ref_lines)

    def search_info(self, user_query):
        # è¿½åŠ æŒ‡ç¤ºï¼šæ±‚äººæ²è¼‰ã‚µã‚¤ãƒˆï¼ˆIndeedã€æ±‚äººãƒœãƒƒã‚¯ã‚¹ã€éšœå®³è€…è»¢è·ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ãƒãƒƒãƒ”ãƒ¼ã€ã‚¹ã‚°JOB ãªã©ï¼‰ã®åç§°ã¯å‡ºåŠ›çµæœã«å«ã‚ãšã€
        # å®Ÿéš›ã«æ±‚äººã‚’å‹Ÿé›†ã—ã¦ã„ã‚‹ä¼æ¥­ã®æƒ…å ±ã®ã¿ã‚’å¯¾è±¡ã«æƒ…å ±ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«æŒ‡ç¤ºã™ã‚‹ã€‚
        enhanced_query = (
            f"{user_query}\n"
            "æ³¨æ„ï¼šæ±‚äººæ²è¼‰ã‚µã‚¤ãƒˆã®åç§°ã¯å‡ºåŠ›çµæœã«å«ã‚ãšã€å®Ÿéš›ã«æ±‚äººã‚’å‡ºã—ã¦ã„ã‚‹ä¼æ¥­ã®æ­£å¼åç§°ã®ã¿ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚\n"
            "ã¾ãŸã€ã‚‚ã—å‡ºåŠ›çµæœãŒã€è¤‡æ•°ã®ä¼æ¥­ã€ã¨ãªã£ã¦ã„ã‚‹å ´åˆã¯ã€ç‰¹ã«å‹¤å‹™åœ°ãŒã€Œå¤§é˜ªåºœæ¢…ç”°æœ¬ç¤¾ã‚ªãƒ•ã‚£ã‚¹ã€ã¨ç¤ºã•ã‚Œã¦ã„ã‚‹ä¼æ¥­ã‚’ä»£è¡¨ä¾‹ã¨ã—ã¦ç‰¹å®šã—ã€ãã®ä¼æ¥­ã®ã¿ã®æƒ…å ±ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
        )
        response = self.search_client.send_message(enhanced_query)
        original_text = ""
        for part in response.candidates[0].content.parts:
            if part.text:
                original_text += part.text + "\n"
        summary_text = self.summary_client(original_text)
        references_text = self.serch_references(response)
        return summary_text, references_text, response

    def post_message_to_slack(self, message):
        headers = {
            "Authorization": f"Bearer {self.slack_bot_token}",
            "Content-Type": "application/json"
        }
        today_date = datetime.now().strftime("%Y-%m-%d")
        for channel in self.slack_channel_id:
            payload = {
                "channel": channel,
                "text": message,
                "unfurl_links": False,
                "unfurl_media": False,
            }
            response = requests.post("https://slack.com/api/chat.postMessage", headers=headers, json=payload)
            data = response.json()
            if data.get("ok"):
                print(f"âœ… {today_date} ã« Slack ã¸ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŠ•ç¨¿ã—ã¾ã—ãŸï¼(ãƒãƒ£ãƒ³ãƒãƒ«: {channel})")
            else:
                print(f"âŒ Slack ã¸ã®æŠ•ç¨¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {data.get('error')} (ãƒãƒ£ãƒ³ãƒãƒ«: {channel})")
                print("è©³ç´°:", data)

    def post_search_result(self, query):
        summary, _, response = self.search_info(query)
        caution_text = "â€»ã“ã‚Œã¯æœ¬æ—¥ã®ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆæƒ…å ±ã‚’ Gemini ãŒæ¤œç´¢ã—ã¦ã¾ã¨ã‚ãŸã‚‚ã®ã§ã‚ã‚Šã€å†…å®¹ã®æ­£ç¢ºæ€§ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
        slack_message = f"*è¦ç´„çµæœ:*\n{summary}\n\n{caution_text}"
        with open(MESSAGE_FILE, "w", encoding="utf-8") as f:
            f.write(slack_message)
        print("æŠ•ç¨¿å†…å®¹:\n", slack_message)
        self.post_message_to_slack(slack_message)
